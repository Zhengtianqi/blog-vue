import{_ as a}from"./plugin-vue_export-helper-c27b6911.js";import{o as e,c as i,a as p}from"./app-0ce632a0.js";const r="/blog-vue/assets/images/Spark.png",t="/blog-vue/assets/images/spark-all.png",l="/blog-vue/assets/images/spark+hdfs.png",o={},s=p('<h1 id="一、spark的核心组件是" tabindex="-1"><a class="header-anchor" href="#一、spark的核心组件是" aria-hidden="true">#</a> 一、Spark的核心组件是：</h1><p>​ 集群资源管理服务（Cluster Manager）</p><p>​ 运行作业任务的节点（WorkerNode），</p><p>​ 每个应用的任务控制节点 Driver 和 每个机器节点上有具有任务的执行进程（Executor）</p><figure><img src="'+r+'" alt="image-20191218134210879" tabindex="0" loading="lazy"><figcaption>image-20191218134210879</figcaption></figure><p>说明：</p><figure><img src="'+t+'" alt="image-20191218140600902" tabindex="0" loading="lazy"><figcaption>image-20191218140600902</figcaption></figure><h1 id="二、关键概念" tabindex="-1"><a class="header-anchor" href="#二、关键概念" aria-hidden="true">#</a> 二、关键概念</h1><p>（1）RDD</p><p>​ Spark 的核心概念是弹性分布式数据集。RDD 是一个只读且不可变的分布式对象集合，创建、转化即调用 RDD 操作者一系列过程贯穿于 Spark 大数据处理的始终。</p><p>（2）DAG</p><p>​ Spark使用有向无环图进行任务调度。</p><p>（3）Spark SQL</p><p>​ 用于结构化数据的计算。</p><p>（4）DataFrame</p><p>​ 分布式的、按照名名列的形式组织的数据集合。</p><p>（5）SQLContext</p><p>​ Spark SQL 提供 SQLContext 封装 Spark 中的所有关系型功能，可以用前面提到的SparkContext创建SQLContext。</p><p>（6）JDBC数据源</p><p>三、Spark 和 HDFS 的配合关系</p><p>​ <img src="'+l+'" alt="image-20191218141731121" loading="lazy"></p><ul><li>（1）读取文件的详细步骤：</li><li>SparkScheduler 与 HDFS 交互获取 File A 的文件信息。</li><li>HDFS返回该文件具体的 Block 信息</li><li>SparkScheduler 根据具体的 Block 数据量，决定一个并行度，创建多个 Task 去读取这些文件Block</li><li>Executor 端执行 Task 并读取具体的 Block，作为 RDD（弹性分部数据集）的一部分</li><li>（2）HDFS文件写入的详细步骤：</li><li>SparkScheduler 创建要写入文件的目录</li><li>根据 RDD 分区分块情况，计算写出数据的 Task 数，并下发这些任务到 Executor</li><li>Executor 执行这些 Task，将具体 RDD 的数据写入到第一步创建的目录下</li></ul>',22),c=[s];function n(k,g){return e(),i("div",null,c)}const _=a(o,[["render",n],["__file","Spark相关概述.html.vue"]]);export{_ as default};
